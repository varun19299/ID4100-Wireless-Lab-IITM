<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width,minimum-scale=1">

  <title>Principles and Techniques of Data Science</title>
  <meta name="description" content="This is the textbook for Data 100, the Principles and Techniques of Data Science course at UC Berkeley.
Data 100 is the upper-division, semester-long data science course that follows Data 8, the Foundations of Data Science. The reader's assumed background is detailed in the About This Book page.">

  <link rel="canonical" href="/ch/10/modeling_loss_functions.html">
  <link rel="alternate" type="application/rss+xml" title="Principles and Techniques of Data Science" href="/feed.xml">

  <meta property="og:url"         content="/ch/10/modeling_loss_functions.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Principles and Techniques of Data Science" />
<meta property="og:description" content="This is the textbook for Data 100, the Principles and Techniques of Data Science course at UC Berkeley.
Data 100 is the upper-division, semester-long data science course that follows Data 8, the Foundations of Data Science. The reader's assumed background is detailed in the About This Book page." />
<meta property="og:image"       content="" />


  <script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "NewsArticle",
  "mainEntityOfPage":
    "/ch/10/modeling_loss_functions.html",
  "headline":
    "Principles and Techniques of Data Science",
  "datePublished":
    "2019-03-03T19:56:01+05:30",
  "dateModified":
    "2019-03-03T19:56:01+05:30",
  "description":
    "This is the textbook for Data 100, the Principles and Techniques of Data Science course at UC Berkeley.
Data 100 is the upper-division, semester-long data science course that follows Data 8, the Foundations of Data Science. The reader's assumed background is detailed in the About This Book page.",
  "author": {
    "@type": "Person",
    "name": "Sam Lau, Joey Gonzalez, and Deborah Nolan"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data 100 at UC Berkeley",
    "logo": {
      "@type": "ImageObject",
      "url": "",
      "width": 60,
      "height": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "",
    "height": 60,
    "width": 60
  }
}

  </script>

  <link rel="stylesheet" href="/assets/css/styles.css">

  <link rel="apple-touch-icon" sizes="57x57" href="/apple-touch-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/apple-touch-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/apple-touch-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/apple-touch-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/apple-touch-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon-180x180.png">
  <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
  <link rel="icon" type="image/png" href="/android-chrome-192x192.png" sizes="192x192">
  <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
  <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
  <!-- <link rel="manifest" href="/manifest.json"> -->
  <!-- <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#efae0a"> -->
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="/mstile-144x144.png">
  <meta name="theme-color" content="#233947">

  <!-- Allow inline math using $ and automatically break long math lines -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
      },
      CommonHTML: {
        linebreaks: {
          automatic: true,
        },
      },
    });
  </script>
  <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_CHTML' async></script>

  <!-- Include Turbolinks to make page loads fast -->
  <!-- https://github.com/turbolinks/turbolinks -->
  <script src="/assets/js/turbolinks.js" async></script>

  <!-- Load nbinteract for widgets -->
  <script src="https://unpkg.com/nbinteract-core" async></script>

  <!-- Load custom website scripts -->
  <script src="/assets/js/scripts.js" async></script>

  <!-- Google analytics -->
  <script src="/assets/js/ga.js" async></script>
</head>

  <body>
    <!-- Show sidebar by default -->
    <div id="js-textbook" class="c-textbook js-show-sidebar">
      




<nav id="js-sidebar" class="c-textbook__sidebar">
  <ul class="c-sidebar__chapters">
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="http://ds100.org/"
        >
          
          Data 100 Homepage
        </a>

        
      </li>

      
    

      
      
        <li class="c-sidebar__divider"></li>
        

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/"
        >
          
          Introduction
        </a>

        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/about_this_book.html"
        >
          
          About This Book
        </a>

        
      </li>

      
    

      
      
        <li class="c-sidebar__divider"></li>
        

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/01/lifecycle_intro.html"
        >
          
            1.
          
          The Data Science Lifecycle
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/01/lifecycle_students_1.html"
                >
                  
                    1.1
                    
                  
                  The Students of Data 100
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/01/lifecycle_students_2.html"
                >
                  
                    1.2
                    
                  
                  Exploring the Data
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/01/lifecycle_students_3.html"
                >
                  
                    1.3
                    
                  
                  What's in a Name?
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/02/design_intro.html"
        >
          
            2.
          
          Data Design
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/02/design_dewey_truman.html"
                >
                  
                    2.1
                    
                  
                  Dewey Defeats Truman
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/02/design_prob_overview.html"
                >
                  
                    2.2
                    
                  
                  Probability Overview
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/02/design_sampling.html"
                >
                  
                    2.3
                    
                  
                  Probability Sampling
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/02/design_srs_vs_big_data.html"
                >
                  
                    2.4
                    
                  
                  SRS vs. "Big Data"
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/03/pandas_intro.html"
        >
          
            3.
          
          Tabular Data and pandas
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/03/pandas_structure.html"
                >
                  
                    3.1
                    
                  
                  Structure
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/03/pandas_indexes.html"
                >
                  
                    3.2
                    
                  
                  Indexes, Slicing, and Sorting
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/03/pandas_grouping_pivoting.html"
                >
                  
                    3.3
                    
                  
                  Grouping and Pivoting
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/03/pandas_apply_strings_plotting.html"
                >
                  
                    3.4
                    
                  
                  Apply, Strings, and Plotting
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/04/eda_intro.html"
        >
          
            4.
          
          Exploratory Data Analysis
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/04/eda_data_types.html"
                >
                  
                    4.1
                    
                  
                  Data Types
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href=""
                >
                  
                    4.2
                    
                  
                  Distributions [in progress]
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href=""
                >
                  
                    4.3
                    
                  
                  Associations [in progress]
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/05/cleaning_intro.html"
        >
          
            5.
          
          Data Cleaning
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/05/cleaning_calls.html"
                >
                  
                    5.1
                    
                  
                  Cleaning the Calls Dataset
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/05/cleaning_stops.html"
                >
                  
                    5.2
                    
                  
                  Cleaning the Stops Dataset
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/05/cleaning_structure.html"
                >
                  
                    5.3
                    
                  
                  Structure and Joins
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/05/cleaning_granularity.html"
                >
                  
                    5.4
                    
                  
                  Granularity
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/05/cleaning_scope.html"
                >
                  
                    5.5
                    
                  
                  Scope
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/05/cleaning_temp.html"
                >
                  
                    5.6
                    
                  
                  Temporality
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/05/cleaning_faithfulness.html"
                >
                  
                    5.7
                    
                  
                  Faithfulness
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/06/viz_intro.html"
        >
          
            6.
          
          Data Visualization
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/06/viz_quantitative.html"
                >
                  
                    6.1
                    
                  
                  Quantitative Data
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/06/viz_qualitative.html"
                >
                  
                    6.2
                    
                  
                  Qualitative Data
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/06/viz_matplotlib.html"
                >
                  
                    6.3
                    
                  
                  Customizing Plots
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/06/viz_principles.html"
                >
                  
                    6.4
                    
                  
                  Principles of Visualization
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/06/viz_principles_2.html"
                >
                  
                    6.5
                    
                  
                  Principles of Visualization 2
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/06/viz_philosophy.html"
                >
                  
                    6.6
                    
                  
                  Visualization Philosophy
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/07/web_intro.html"
        >
          
            7.
          
          Web Technologies
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/07/web_http.html"
                >
                  
                    7.1
                    
                  
                  HTTP
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/08/text_intro.html"
        >
          
            8.
          
          Working With Text
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/08/text_strings.html"
                >
                  
                    8.1
                    
                  
                  Python String Methods
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/08/text_regex.html"
                >
                  
                    8.2
                    
                  
                  Regular Expressions
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/08/text_re.html"
                >
                  
                    8.3
                    
                  
                  Regex in Python and pandas
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/09/sql_intro.html"
        >
          
            9.
          
          Databases and SQL
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/09/sql_rdbms.html"
                >
                  
                    9.1
                    
                  
                  Relational Databases
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/09/sql_basics.html"
                >
                  
                    9.2
                    
                  
                  SQL Queries
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/09/sql_joins.html"
                >
                  
                    9.3
                    
                  
                  SQL Joins
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/10/modeling_intro.html"
        >
          
            10.
          
          Modeling and Estimation
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections ">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/10/modeling_simple.html"
                >
                  
                    10.1
                    
                  
                  A Simple Model
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry c-sidebar__entry--active"
                  href="/ch/10/modeling_loss_functions.html"
                >
                  
                    10.2
                    
                  
                  Loss Functions
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/10/modeling_abs_huber.html"
                >
                  
                    10.3
                    
                  
                  Absolute Cost and Huber Cost
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/11/gradient_descent.html"
        >
          
            11.
          
          Gradient Descent
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/11/gradient_basics.html"
                >
                  
                    11.1
                    
                  
                  Basic Numerical Optimization
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/11/gradient_descent_define.html"
                >
                  
                    11.2
                    
                  
                  Defining Gradient Descent
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/11/gradient_convexity.html"
                >
                  
                    11.3
                    
                  
                  Convexity
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/11/gradient_stochastic.html"
                >
                  
                    11.4
                    
                  
                  Stochastic Gradient Descent
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/12/prob_and_gen.html"
        >
          
            12.
          
          Probability and Generalization
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/12/prob_random_vars.html"
                >
                  
                    12.1
                    
                  
                  Random Variables
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/12/prob_exp_var.html"
                >
                  
                    12.2
                    
                  
                  Expectation and Variance
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/12/prob_risk.html"
                >
                  
                    12.3
                    
                  
                  Risk
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/13/linear_models.html"
        >
          
            13.
          
          Linear Regression
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/13/linear_tips.html"
                >
                  
                    13.1
                    
                  
                  Defining a Simple Linear Model
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/13/linear_grad.html"
                >
                  
                    13.2
                    
                  
                  Fitting the Model
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/13/linear_multiple.html"
                >
                  
                    13.3
                    
                  
                  Multiple Linear Regression
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/13/linear_projection.html"
                >
                  
                    13.4
                    
                  
                  A Geometric Perspective
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/13/linear_case_study.html"
                >
                  
                    13.5
                    
                  
                  Linear Regression Case Study
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/14/feature_engineering.html"
        >
          
            14.
          
          Feature Engineering
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/14/feature_one_hot.html"
                >
                  
                    14.1
                    
                  
                  One-Hot Encoding
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/14/feature_polynomial.html"
                >
                  
                    14.2
                    
                  
                  Polynomial Regression
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/15/bias_intro.html"
        >
          
            15.
          
          Bias-Variance Tradeoff
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/15/bias_risk.html"
                >
                  
                    15.1
                    
                  
                  Risk and Cost Minimization
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/15/bias_modeling.html"
                >
                  
                    15.2
                    
                  
                  Model Bias and Variance
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/15/bias_cv.html"
                >
                  
                    15.3
                    
                  
                  Cross Validation
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/16/reg_intro.html"
        >
          
            16.
          
          Regularization
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/16/reg_intuition.html"
                >
                  
                    16.1
                    
                  
                  Regularization Intuition
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/16/reg_ridge.html"
                >
                  
                    16.2
                    
                  
                  L2 Regularization
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/16/reg_lasso.html"
                >
                  
                    16.3
                    
                  
                  L1 Regularization
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/17/classification_intro.html"
        >
          
            17.
          
          Classification
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/17/classification_prob.html"
                >
                  
                    17.1
                    
                  
                  Regression on Probabilities
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/17/classification_log_model.html"
                >
                  
                    17.2
                    
                  
                  Logistic Model
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/17/classification_cost.html"
                >
                  
                    17.3
                    
                  
                  Cross-Entropy Loss
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/17/classification_log_reg.html"
                >
                  
                    17.4
                    
                  
                  Using Logistic Regression
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/17/classification_cost_justification.html"
                >
                  
                    17.5
                    
                  
                  Justifying Cross-Entropy Loss
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/17/classification_sgd.html"
                >
                  
                    17.6
                    
                  
                  Fitting a Logistic Model
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/17/classification_sensitivity_specificity.html"
                >
                  
                    17.7
                    
                  
                  Evaluating Logistic Models
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/17/classification_multiclass.html"
                >
                  
                    17.8
                    
                  
                  Multiclass Classification
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/18/hyp_intro.html"
        >
          
            18.
          
          Statistical Inference
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/18/hyp_introduction.html"
                >
                  
                    18.1
                    
                  
                  Introduction to Hypothesis Testing
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/18/hyp_introduction_part2.html"
                >
                  
                    18.2
                    
                  
                  Permutation Testing
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/18/hyp_regression.html"
                >
                  
                    18.3
                    
                  
                  Bootstrapping for Linear Regression
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/18/hyp_studentized.html"
                >
                  
                    18.4
                    
                  
                  Studentized Bootstrap
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/18/hyp_phacking.html"
                >
                  
                    18.5
                    
                  
                  P-Hacking
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      
        <li class="c-sidebar__divider"></li>
        

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/19/vector_space_review.html"
        >
          
          Appendix: Vector Space Review
        </a>

        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/20/ref_intro.html"
        >
          
          Appendix: Reference Tables
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/20/ref_pandas.html"
                >
                  
                  pandas
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/20/ref_seaborn.html"
                >
                  
                  seaborn
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/20/ref_matplotlib.html"
                >
                  
                  matplotlib
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/20/ref_sklearn.html"
                >
                  
                  scikit-learn
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/21/contributors.html"
        >
          
          Appendix: Contributors
        </a>

        
      </li>

      
    
  </ul>
</nav>


      <main class="c-textbook__page" tabindex="-1">
        <div class="o-wrapper c-sidebar-toggle">
  <!-- We show the sidebar by default so we use .is-active -->
  <button
    id="js-sidebar-toggle"
    class="hamburger hamburger--arrowalt is-active"
  >
    <span class="hamburger-box">
      <span class="hamburger-inner"></span>
    </span>
    <span class="c-sidebar-toggle__label">Toggle Sidebar</span>
  </button>
</div>

        <div class="o-wrapper">
          

<div id="ipython-notebook">
    <div class="buttons">
        <button class="interact-button js-nbinteract-widget">
            Show Widgets
        </button>
        <a class="interact-button" href="http://data100.datahub.berkeley.edu/user-redirect/git-pull?repo=https://github.com/DS-100/textbook&subPath=notebooks/10/modeling_loss_functions.ipynb">Open on DataHub</a>
    </div>
    







  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="c1"># Clear previously defined variables</span>
<span class="o">%</span><span class="k">reset</span> -f

<span class="c1"># Set directory for data loading to work properly</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/notebooks/10&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

  </div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="c1"># Ignore numpy dtype warnings. These warnings are caused by an interaction</span>
<span class="c1"># between numpy and Cython and can be safely ignored.</span>
<span class="c1"># Reference: https://stackoverflow.com/a/40846742</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;numpy.dtype size changed&quot;</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;numpy.ufunc size changed&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="k">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">fixed</span><span class="p">,</span> <span class="n">interact_manual</span>
<span class="kn">import</span> <span class="nn">nbinteract</span> <span class="k">as</span> <span class="nn">nbi</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s1">&#39;talk&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_columns</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="c1"># This option stops scientific notation for pandas</span>
<span class="c1"># pd.set_option(&#39;display.float_format&#39;, &#39;{:.2f}&#39;.format)</span>
</pre></div>

    </div>
</div>
</div>

  </div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">tips</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;tips&#39;</span><span class="p">)</span>
<span class="n">tips</span><span class="p">[</span><span class="s1">&#39;pcttip&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tips</span><span class="p">[</span><span class="s1">&#39;tip&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">tips</span><span class="p">[</span><span class="s1">&#39;total_bill&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span>
</pre></div>

    </div>
</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loss-Functions">Loss Functions<a class="anchor-link" href="#Loss-Functions">&#182;</a></h2><p>Recall our assumptions thus far: we assume that there is a single population tip percentage $ \theta^* $. Our model estimates this parameter; we use the variable $ \theta $ to denote our estimate. We would like to use the collected data on tips to determine the value that $ \theta $ should have,</p>
<p>To precisely decide which value of $ \theta $ is best, we define a <strong>loss function</strong>. A loss function is a mathematical function that takes in an estimate $ \theta $ and the points in our dataset $y_1, y_2, \ldots, y_n$. It outputs a single number, the <strong>loss</strong>, that measures how well $ \theta $ fits our data. In mathematical notation, we want to create the function:</p>
<p>$$ L(\theta, y_1, y_2, \ldots, y_n) =\ \ldots $$</p>
<p>By convention, the loss function outputs lower values for preferable values of $ \theta $ and larger values for worse values of $ \theta $. To fit our model, we select the value of $ \theta $ that produces a lower loss than all other choices of $ \theta $—the $ \theta $ that <strong>minimizes the loss</strong>. We use the notation $ \hat{\theta} $ to denote the value of $ \theta $ that minimizes a specified loss function.</p>
<p>Consider once again two possible values of $ \theta $: $ \theta = 10 $ and $ \theta = 15 $.</p>

</div>
</div>
</div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">tips</span><span class="p">[</span><span class="s1">&#39;pcttip&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span> <span class="n">rug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$ \theta = 10$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;darkgreen&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$ \theta = 15$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Percent Tip Amount&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Proportion per Percent&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_png output_subarea ">
<img src="/notebooks-images/modeling_loss_functions_4_0.png"
>
</div>

</div>

</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since $ \theta = 15 $ falls closer to most of the points, our loss function should output a small value for $ \theta = 15 $ and a larger value for $ \theta = 10 $.</p>
<p>Let's use this intuition to create a loss function.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Our-First-Loss-Function:-Mean-Squared-Error">Our First Loss Function: Mean Squared Error<a class="anchor-link" href="#Our-First-Loss-Function:-Mean-Squared-Error">&#182;</a></h3><p>We would like our choice of $ \theta $ to fall close to the points in our dataset. Thus, we can define a loss function that outputs a larger value as $ \theta $ gets further away from the points in the dataset. We start with a simple loss function called the <em>mean squared error</em>. Here's the idea:</p>
<ol>
<li>We select a value of $ \theta $.</li>
<li>For each value in our dataset, take the squared difference between the value and theta: $ (y_i - \theta)^2 $ . Squaring the difference in a simple way to convert negative differences into positive ones. We want to do this because if our point $ y_i = 14 $, $ \theta = 10 $ and $ \theta = 18 $ are equally far away from the point and are thus equally "bad".</li>
<li>To compute the final loss, take the average of each of the individual squared differences.</li>
</ol>
<p>This gives us a final loss function of:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$$
\begin{aligned}
L(\theta, y_1, y_2, \ldots, y_n)
&amp;= \text{average}\left\{ (y_1 - \theta)^2, (y_2 - \theta)^2, \ldots, (y_n - \theta)^2 \right\} \\
&amp;= \frac{1}{n} \left((y_1 - \theta)^2 + (y_2 - \theta)^2 + \ldots + (y_n - \theta)^2 \right) \\
&amp;= \frac{1}{n} \sum_{i = 1}^{n}(y_i - \theta)^2\\
\end{aligned}
$$</p>
<p>Creating a Python function to compute the loss is simple:</p>

</div>
</div>
</div>

  

  <div class="
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">mse_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_vals</span> <span class="o">-</span> <span class="n">theta</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's see how this loss function behaves. Suppose we have a dataset only containing one point, $ y_1 = 14 $. We can try different values of $ \theta $ and see what the loss function outputs for each value.</p>

</div>
</div>
</div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="k">def</span> <span class="nf">try_thetas</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">,</span> <span class="n">xlims</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">mse_loss</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">cols</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_vals</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">y_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_vals</span><span class="p">)</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">thetas</span><span class="p">)</span> <span class="o">/</span> <span class="n">cols</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">theta</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">thetas</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">rugplot</span><span class="p">(</span><span class="n">y_vals</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="n">rf</span><span class="s1">&#39;$ </span><span class="se">\t</span><span class="s1">heta = </span><span class="si">{theta}</span><span class="s1"> $&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Loss = {loss_fn(theta, y_vals):.2f}&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">*</span><span class="n">xlims</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="n">try_thetas</span><span class="p">(</span><span class="n">thetas</span><span class="o">=</span><span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span>
           <span class="n">y_vals</span><span class="o">=</span><span class="p">[</span><span class="mi">14</span><span class="p">],</span> <span class="n">xlims</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">17</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_png output_subarea ">
<img src="/notebooks-images/modeling_loss_functions_10_0.png"
>
</div>

</div>

</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can also interactively try different values of $ \theta $ below. You should understand why the loss for $ \theta = 11 $ is many times higher than the loss for $ \theta = 13 $.</p>

</div>
</div>
</div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="k">def</span> <span class="nf">try_thetas_interact</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">,</span> <span class="n">xlims</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">mse_loss</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_vals</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">y_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_vals</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">rugplot</span><span class="p">(</span><span class="n">y_vals</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">*</span><span class="n">xlims</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Loss for theta = </span><span class="si">{theta}</span><span class="s1">: {loss_fn(theta, y_vals):.2f}&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">mse_interact</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">,</span> <span class="n">xlims</span><span class="p">):</span>
    <span class="n">plot</span> <span class="o">=</span> <span class="n">interactive</span><span class="p">(</span><span class="n">try_thetas_interact</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="n">theta</span><span class="p">,</span>
                       <span class="n">y_vals</span><span class="o">=</span><span class="n">fixed</span><span class="p">(</span><span class="n">y_vals</span><span class="p">),</span> <span class="n">xlims</span><span class="o">=</span><span class="n">fixed</span><span class="p">(</span><span class="n">xlims</span><span class="p">),</span>
                       <span class="n">loss_fn</span><span class="o">=</span><span class="n">fixed</span><span class="p">(</span><span class="n">mse_loss</span><span class="p">))</span>
    <span class="n">plot</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">layout</span><span class="o">.</span><span class="n">height</span> <span class="o">=</span> <span class="s1">&#39;240px&#39;</span>
    <span class="k">return</span> <span class="n">plot</span>
    
<span class="n">mse_interact</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">y_vals</span><span class="o">=</span><span class="p">[</span><span class="mi">14</span><span class="p">],</span> <span class="n">xlims</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">17</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



  <div class="output_subarea output_widget_view ">
    <button class="js-nbinteract-widget">
      Loading widgets...
    </button>
  </div>

</div>

</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As we hoped, our loss is larger as $ \theta $ is further away from our data and is smallest when $ \theta $ falls exactly onto our data point. Let's now see how our mean squared error behaves when we have five points instead of one. Our data this time are: $ [11, 12, 15, 17, 18 ] $.</p>

</div>
</div>
</div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">try_thetas</span><span class="p">(</span><span class="n">thetas</span><span class="o">=</span><span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">],</span>
           <span class="n">y_vals</span><span class="o">=</span><span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">],</span>
           <span class="n">xlims</span><span class="o">=</span><span class="p">(</span><span class="mf">10.5</span><span class="p">,</span> <span class="mf">18.5</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_png output_subarea ">
<img src="/notebooks-images/modeling_loss_functions_14_0.png"
>
</div>

</div>

</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Of the values of $ \theta $ we tried $ \theta = 15 $ has the lowest loss. However, a value of $ \theta $ in between 14 and 15 might have an even lower loss than $ \theta = 15 $. See if you can find a better value of $ \theta $ using the interactive plot below.</p>

</div>
</div>
</div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">mse_interact</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span>
             <span class="n">y_vals</span><span class="o">=</span><span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">],</span>
             <span class="n">xlims</span><span class="o">=</span><span class="p">(</span><span class="mf">10.5</span><span class="p">,</span> <span class="mf">18.5</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



  <div class="output_subarea output_widget_view ">
    <button class="js-nbinteract-widget">
      Loading widgets...
    </button>
  </div>

</div>

</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The mean squared error seems to be doing its job by penalizing values of $ \theta $ that are far away from the center of the data. Let's now see what the loss function outputs on the original dataset of tip percents. For reference, the original distribution of tip percents is plotted below:</p>

</div>
</div>
</div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">tips</span><span class="p">[</span><span class="s1">&#39;pcttip&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span> <span class="n">rug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Percent Tip Amount&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Proportion per Percent&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_png output_subarea ">
<img src="/notebooks-images/modeling_loss_functions_18_0.png"
>
</div>

</div>

</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's try some values of $ \theta $.</p>

</div>
</div>
</div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">try_thetas</span><span class="p">(</span><span class="n">thetas</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">14.5</span><span class="p">,</span> <span class="mf">17.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
           <span class="n">y_vals</span><span class="o">=</span><span class="n">tips</span><span class="p">[</span><span class="s1">&#39;pcttip&#39;</span><span class="p">],</span>
           <span class="n">xlims</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_png output_subarea ">
<img src="/notebooks-images/modeling_loss_functions_20_0.png"
>
</div>

</div>

</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As before, we've created an interactive widget to test different values of $ \theta $.</p>

</div>
</div>
</div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">mse_interact</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">),</span>
             <span class="n">y_vals</span><span class="o">=</span><span class="n">tips</span><span class="p">[</span><span class="s1">&#39;pcttip&#39;</span><span class="p">],</span>
             <span class="n">xlims</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



  <div class="output_subarea output_widget_view ">
    <button class="js-nbinteract-widget">
      Loading widgets...
    </button>
  </div>

</div>

</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It looks like the best value of $ \theta $ that we've tried so far is 16.00, slightly above our original guess of 15% tip.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="A-Shorthand">A Shorthand<a class="anchor-link" href="#A-Shorthand">&#182;</a></h3><p>We have defined our first loss function, the mean squared error (MSE). It computes high loss for values of $ \theta $ that are further away from the center of the data. Mathematically, this loss function is defined as:</p>
<p>$$
\begin{aligned}
L(\theta, y_1, y_2, \ldots, y_n)
&amp;= \frac{1}{n} \sum_{i = 1}^{n}(y_i - \theta)^2\\
\end{aligned}
$$</p>
<p>The loss function will compute different losses whenever we change either $ \theta $ or $ y_1, y_2, \ldots, y_n $. We've seen this happen when we tried different values of $ \theta $ and when we added new data points (changing $ y_1, y_2, \ldots, y_n $).</p>
<p>As a shorthand, we can define the vector $ \textbf{y} = [ y_1, y_2, \ldots, y_n ] $. Then, we can write MSE as:</p>
<p>$$
\begin{aligned}
L(\theta, \textbf{y})
&amp;= \frac{1}{n} \sum_{i = 1}^{n}(y_i - \theta)^2\\
\end{aligned}
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Minimizing-the-Loss">Minimizing the Loss<a class="anchor-link" href="#Minimizing-the-Loss">&#182;</a></h3><p>So far, we have found the best value of $ \theta $ by simply trying out a bunch of values and then picking the one with the least loss. Although this method works decently well, we can find a better method by using the properties of our loss function.</p>
<p>For the following example, we use a dataset containing five points: $ \textbf{y} = [ 11, 12, 15, 16, 17 ] $.</p>

</div>
</div>
</div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">try_thetas</span><span class="p">(</span><span class="n">thetas</span><span class="o">=</span><span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">],</span>
           <span class="n">y_vals</span><span class="o">=</span><span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">],</span>
           <span class="n">xlims</span><span class="o">=</span><span class="p">(</span><span class="mf">10.5</span><span class="p">,</span> <span class="mf">18.5</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_png output_subarea ">
<img src="/notebooks-images/modeling_loss_functions_26_0.png"
>
</div>

</div>

</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the plots above, we've used integer $ \theta $ values in between 12 and 17. When we change $ \theta $, the loss seems to start high (at 10.92), decrease until $ \theta = 15 $, then increase again. We can see that the loss changes as $ \theta $ changes, so let's make a plot comparing the loss to $ \theta $ for each of the six $ \theta $s we've tried.</p>

</div>
</div>
</div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">thetas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">])</span>
<span class="n">y_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">])</span>
<span class="n">losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span> <span class="k">for</span> <span class="n">theta</span> <span class="ow">in</span> <span class="n">thetas</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Loss vs. $ \theta $ when $\bf</span><span class="si">{y}</span><span class="s1">$$ = [11, 12, 15, 17, 18] $&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$ \theta $ Values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_png output_subarea ">
<img src="/notebooks-images/modeling_loss_functions_28_0.png"
>
</div>

</div>

</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The scatter plot shows the downward, then upward trend that we noticed before. We can try more values of $ \theta $ to see a complete curve that shows how the loss changes as $ \theta $ changes.</p>

</div>
</div>
</div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">thetas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mf">17.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>
<span class="n">y_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">])</span>
<span class="n">losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span> <span class="k">for</span> <span class="n">theta</span> <span class="ow">in</span> <span class="n">thetas</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Loss vs. $ \theta $ when $\bf</span><span class="si">{y}</span><span class="s1">$$ = [11, 12, 15, 17, 18] $&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$ \theta $ Values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_png output_subarea ">
<img src="/notebooks-images/modeling_loss_functions_30_0.png"
>
</div>

</div>

</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The plot above shows that in fact, $ \theta = 15$ was not the best choice; a $ \theta $ between 14 and 15 would have gotten a lower loss. We can use calculus to find that minimizing value of $ \theta $ exactly. At the minimum loss, the derivative of the loss function with respect to $ \theta $ is 0.</p>
<p>First, we start with our loss function:</p>
<p>$$
\begin{aligned}
L(\theta, \textbf{y})
&amp;= \frac{1}{n} \sum_{i = 1}^{n}(y_i - \theta)^2\\
\end{aligned}
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we plug in our points $ \textbf{y} = [11, 12, 15, 17, 18] $:</p>
<p>$$
\begin{aligned}
L(\theta, \textbf{y})
&amp;= \frac{1}{5} \big((11 - \theta)^2 + (12 - \theta)^2 + (15 - \theta)^2 + (17 - \theta)^2 + (18 - \theta)^2 \big)\\
\end{aligned}
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To find the value of $ \theta $ that minimizes this function, we compute the derivative with respect to $ \theta $:</p>
<p>$$
\begin{aligned}
\frac{\partial}{\partial \theta} L(\theta, \textbf{y})
&amp;= \frac{1}{5} \big(-2(11 - \theta) - 2(12 - \theta) - 2(15 - \theta) - 2(17 - \theta) -2(18 - \theta) \big)\\
&amp;= \frac{1}{5} \big(10 \cdot \theta - 146 \big)\\
\end{aligned}
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then, we find the value of $ \theta $ where the derivative is zero:</p>
<p>$$
\begin{aligned}
\frac{1}{5} \big(10 \cdot \theta - 146 \big) &amp;= 0 \\
10 \cdot \theta - 146 &amp;= 0 \\
\theta &amp;= 14.6
\end{aligned}
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We've found the minimizing $ \theta $, and as expected, it is between 14 and 15. We denote the $ \theta $ that minimizes the loss $ \hat{\theta} $. Thus, for the dataset $ \textbf{y} = [11, 12, 15, 17, 18] $ and the MSE loss function:</p>
<p>$$ \hat{\theta} = 14.6 $$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If we happen to compute the mean of the data values, we notice a curious equivalence:</p>
<p>$$ \text{mean} (\textbf{y}) = \hat{\theta} = 14.6 $$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-Minimizing-Value-of-the-Mean-Squared-Error">The Minimizing Value of the Mean Squared Error<a class="anchor-link" href="#The-Minimizing-Value-of-the-Mean-Squared-Error">&#182;</a></h3><p>As it turns out, the equivalence above is no mere coincidence; the average of the data values <em>always</em> produces $ \hat{\theta} $, the $ \theta $ that minimizes the MSE loss.</p>
<p>To show this, we take the derivative of our loss function once more. Instead of plugging in points, we leave the $ y_i $ terms intact to generalize to other datasets.</p>
<p>$$
\begin{aligned}
L(\theta, \textbf{y})
&amp;= \frac{1}{n} \sum_{i = 1}^{n}(y_i - \theta)^2\\
\frac{\partial}{\partial \theta} L(\theta, \textbf{y})
&amp;= \frac{1}{n} \sum_{i = 1}^{n} -2(y_i - \theta) \\
&amp;= -\frac{2}{n} \sum_{i = 1}^{n} (y_i - \theta) \\
\end{aligned}
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since we did not substitute in specific values for $ y_i $, this equation can be used with any dataset with any number of points.</p>
<p>Now, we set the derivative equal to zero and solve for $ \theta $ to find the minimizing value of $ \theta $ as before:</p>
<p>$$
\begin{aligned}
-\frac{2}{n} \sum_{i = 1}^{n} (y_i - \theta) &amp;= 0 \\
\sum_{i = 1}^{n} (y_i - \theta) &amp;= 0 \\
\sum_{i = 1}^{n} y_i - \sum_{i = 1}^{n} \theta &amp;= 0 \\
\sum_{i = 1}^{n} \theta &amp;= \sum_{i = 1}^{n} y_i \\
n \cdot \theta &amp;= y_1 + \ldots + y_n \\
\theta &amp;= \frac{y_1 + \ldots + y_n}{n} \\
\hat \theta = \theta &amp;= \text{mean} (\textbf{y})
\end{aligned}
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lo and behold, we see that there is a single value of $ \theta $ that gives the least MSE no matter what the dataset is. For the mean squared error, we know that $ \hat{\theta} $ is the mean of the dataset values.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Back-to-the-Original-Dataset">Back to the Original Dataset<a class="anchor-link" href="#Back-to-the-Original-Dataset">&#182;</a></h3><p>We no longer have to test out different values of $ \theta $ as we did before. We can compute the mean tip percentage in one go:</p>

</div>
</div>
</div>

  

  <div class="
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">tips</span><span class="p">[</span><span class="s1">&#39;pcttip&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_text output_subarea output_execute_result">
<pre>16.080258172250463</pre>
</div>

</div>

</div>
</div>

  </div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">tips</span><span class="p">[</span><span class="s1">&#39;pcttip&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span> <span class="n">rug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mf">16.08</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$ \hat \theta = 16.08$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of tip percent&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Percent Tip Amount&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Proportion per Percent&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_png output_subarea ">
<img src="/notebooks-images/modeling_loss_functions_42_0.png"
>
</div>

</div>

</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Summary">Summary<a class="anchor-link" href="#Summary">&#182;</a></h3><p>We have introduced a <strong>constant model</strong>, a model that outputs the same number for all entries in the dataset.</p>
<p>A <strong>loss function</strong> $ L(\theta, \textbf{y}) $ measures how well a given value of $ \theta $ fits the data. In this section, we introduce the mean squared error loss function and showed that $ \hat{\theta} = \text{mean}(\textbf{y}) $ for the constant model.</p>
<p>The steps we took in this section apply to many modeling scenarios:</p>
<ol>
<li>Select a model.</li>
<li>Select a loss function.</li>
<li>Fit the model by minimizing the loss.</li>
</ol>
<p>In this book, all of our modeling techniques expand upon one or more of these steps. We introduce new models (1), new loss functions (2), and new techniques for minimizing loss (3).</p>

</div>
</div>
</div>


</div>



          <nav class="c-page__nav">
  
    <a id="js-page__nav__prev" class="c-page__nav__prev" href="/ch/10/modeling_simple.html">
      〈 <span class="u-margin-right-tiny"></span> Previous
    </a>
  

  
    <a id="js-page__nav__next" class="c-page__nav__next" href="/ch/10/modeling_abs_huber.html">
      Next <span class="u-margin-right-tiny"></span> 〉
    </a>
  
</nav>

        </div>
      </main>
    </div>

    <script>
      window.ga =
  window.ga ||
  function() {
    ;(ga.q = ga.q || []).push(arguments)
  }
ga.l = +new Date()
ga('create', 'UA-113006011-1', 'auto')
ga('send', 'pageview')

    </script>
  </body>
</html>
