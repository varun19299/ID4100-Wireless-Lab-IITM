<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width,minimum-scale=1">

  <title>Principles and Techniques of Data Science</title>
  <meta name="description" content="This is the textbook for Data 100, the Principles and Techniques of Data Science course at UC Berkeley.
Data 100 is the upper-division, semester-long data science course that follows Data 8, the Foundations of Data Science. The reader's assumed background is detailed in the About This Book page.">

  <link rel="canonical" href="https://varun19299.github.io//id4100-intro-to-wireless/ch/15/bias_modeling.html">
  <link rel="alternate" type="application/rss+xml" title="Principles and Techniques of Data Science" href="https://varun19299.github.io//id4100-intro-to-wireless/feed.xml">

  <meta property="og:url"         content="https://varun19299.github.io//id4100-intro-to-wireless/ch/15/bias_modeling.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Principles and Techniques of Data Science" />
<meta property="og:description" content="This is the textbook for Data 100, the Principles and Techniques of Data Science course at UC Berkeley.
Data 100 is the upper-division, semester-long data science course that follows Data 8, the Foundations of Data Science. The reader's assumed background is detailed in the About This Book page." />
<meta property="og:image"       content="" />


  <script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "NewsArticle",
  "mainEntityOfPage":
    "https://varun19299.github.io//id4100-intro-to-wireless/ch/15/bias_modeling.html",
  "headline":
    "Principles and Techniques of Data Science",
  "datePublished":
    "2019-03-03T20:17:49+05:30",
  "dateModified":
    "2019-03-03T20:17:49+05:30",
  "description":
    "This is the textbook for Data 100, the Principles and Techniques of Data Science course at UC Berkeley.
Data 100 is the upper-division, semester-long data science course that follows Data 8, the Foundations of Data Science. The reader's assumed background is detailed in the About This Book page.",
  "author": {
    "@type": "Person",
    "name": "Sam Lau, Joey Gonzalez, and Deborah Nolan"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data 100 at UC Berkeley",
    "logo": {
      "@type": "ImageObject",
      "url": "https://varun19299.github.io//id4100-intro-to-wireless",
      "width": 60,
      "height": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "https://varun19299.github.io//id4100-intro-to-wireless",
    "height": 60,
    "width": 60
  }
}

  </script>

  <link rel="stylesheet" href="/assets/css/styles.css">

  <link rel="apple-touch-icon" sizes="57x57" href="/apple-touch-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/apple-touch-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/apple-touch-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/apple-touch-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/apple-touch-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon-180x180.png">
  <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
  <link rel="icon" type="image/png" href="/android-chrome-192x192.png" sizes="192x192">
  <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
  <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
  <!-- <link rel="manifest" href="/manifest.json"> -->
  <!-- <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#efae0a"> -->
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="/mstile-144x144.png">
  <meta name="theme-color" content="#233947">

  <!-- Allow inline math using $ and automatically break long math lines -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
      },
      CommonHTML: {
        linebreaks: {
          automatic: true,
        },
      },
    });
  </script>
  <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_CHTML' async></script>

  <!-- Include Turbolinks to make page loads fast -->
  <!-- https://github.com/turbolinks/turbolinks -->
  <script src="/assets/js/turbolinks.js" async></script>

  <!-- Load nbinteract for widgets -->
  <script src="https://unpkg.com/nbinteract-core" async></script>

  <!-- Load custom website scripts -->
  <script src="/assets/js/scripts.js" async></script>

  <!-- Google analytics -->
  <script src="/assets/js/ga.js" async></script>
</head>

  <body>
    <!-- Show sidebar by default -->
    <div id="js-textbook" class="c-textbook js-show-sidebar">
      




<nav id="js-sidebar" class="c-textbook__sidebar">
  <ul class="c-sidebar__chapters">
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="http://ds100.org/"
        >
          
          Data 100 Homepage
        </a>

        
      </li>

      
    

      
      
        <li class="c-sidebar__divider"></li>
        

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/"
        >
          
          Introduction
        </a>

        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/about_this_book.html"
        >
          
          About This Book
        </a>

        
      </li>

      
    

      
      
        <li class="c-sidebar__divider"></li>
        

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/01/lifecycle_intro.html"
        >
          
            1.
          
          The Data Science Lifecycle
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/01/lifecycle_students_1.html"
                >
                  
                    1.1
                    
                  
                  The Students of Data 100
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/01/lifecycle_students_2.html"
                >
                  
                    1.2
                    
                  
                  Exploring the Data
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/01/lifecycle_students_3.html"
                >
                  
                    1.3
                    
                  
                  What's in a Name?
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/02/design_intro.html"
        >
          
            2.
          
          Data Design
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/02/design_dewey_truman.html"
                >
                  
                    2.1
                    
                  
                  Dewey Defeats Truman
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/02/design_prob_overview.html"
                >
                  
                    2.2
                    
                  
                  Probability Overview
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/02/design_sampling.html"
                >
                  
                    2.3
                    
                  
                  Probability Sampling
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/02/design_srs_vs_big_data.html"
                >
                  
                    2.4
                    
                  
                  SRS vs. "Big Data"
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/03/pandas_intro.html"
        >
          
            3.
          
          Tabular Data and pandas
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/03/pandas_structure.html"
                >
                  
                    3.1
                    
                  
                  Structure
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/03/pandas_indexes.html"
                >
                  
                    3.2
                    
                  
                  Indexes, Slicing, and Sorting
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/03/pandas_grouping_pivoting.html"
                >
                  
                    3.3
                    
                  
                  Grouping and Pivoting
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/03/pandas_apply_strings_plotting.html"
                >
                  
                    3.4
                    
                  
                  Apply, Strings, and Plotting
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/04/eda_intro.html"
        >
          
            4.
          
          Exploratory Data Analysis
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/04/eda_data_types.html"
                >
                  
                    4.1
                    
                  
                  Data Types
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href=""
                >
                  
                    4.2
                    
                  
                  Distributions [in progress]
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href=""
                >
                  
                    4.3
                    
                  
                  Associations [in progress]
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/05/cleaning_intro.html"
        >
          
            5.
          
          Data Cleaning
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/05/cleaning_calls.html"
                >
                  
                    5.1
                    
                  
                  Cleaning the Calls Dataset
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/05/cleaning_stops.html"
                >
                  
                    5.2
                    
                  
                  Cleaning the Stops Dataset
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/05/cleaning_structure.html"
                >
                  
                    5.3
                    
                  
                  Structure and Joins
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/05/cleaning_granularity.html"
                >
                  
                    5.4
                    
                  
                  Granularity
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/05/cleaning_scope.html"
                >
                  
                    5.5
                    
                  
                  Scope
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/05/cleaning_temp.html"
                >
                  
                    5.6
                    
                  
                  Temporality
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/05/cleaning_faithfulness.html"
                >
                  
                    5.7
                    
                  
                  Faithfulness
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/06/viz_intro.html"
        >
          
            6.
          
          Data Visualization
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/06/viz_quantitative.html"
                >
                  
                    6.1
                    
                  
                  Quantitative Data
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/06/viz_qualitative.html"
                >
                  
                    6.2
                    
                  
                  Qualitative Data
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/06/viz_matplotlib.html"
                >
                  
                    6.3
                    
                  
                  Customizing Plots
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/06/viz_principles.html"
                >
                  
                    6.4
                    
                  
                  Principles of Visualization
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/06/viz_principles_2.html"
                >
                  
                    6.5
                    
                  
                  Principles of Visualization 2
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/06/viz_philosophy.html"
                >
                  
                    6.6
                    
                  
                  Visualization Philosophy
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/07/web_intro.html"
        >
          
            7.
          
          Web Technologies
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/07/web_http.html"
                >
                  
                    7.1
                    
                  
                  HTTP
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/08/text_intro.html"
        >
          
            8.
          
          Working With Text
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/08/text_strings.html"
                >
                  
                    8.1
                    
                  
                  Python String Methods
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/08/text_regex.html"
                >
                  
                    8.2
                    
                  
                  Regular Expressions
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/08/text_re.html"
                >
                  
                    8.3
                    
                  
                  Regex in Python and pandas
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/09/sql_intro.html"
        >
          
            9.
          
          Databases and SQL
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/09/sql_rdbms.html"
                >
                  
                    9.1
                    
                  
                  Relational Databases
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/09/sql_basics.html"
                >
                  
                    9.2
                    
                  
                  SQL Queries
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/09/sql_joins.html"
                >
                  
                    9.3
                    
                  
                  SQL Joins
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/10/modeling_intro.html"
        >
          
            10.
          
          Modeling and Estimation
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/10/modeling_simple.html"
                >
                  
                    10.1
                    
                  
                  A Simple Model
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/10/modeling_loss_functions.html"
                >
                  
                    10.2
                    
                  
                  Loss Functions
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/10/modeling_abs_huber.html"
                >
                  
                    10.3
                    
                  
                  Absolute Cost and Huber Cost
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/11/gradient_descent.html"
        >
          
            11.
          
          Gradient Descent
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/11/gradient_basics.html"
                >
                  
                    11.1
                    
                  
                  Basic Numerical Optimization
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/11/gradient_descent_define.html"
                >
                  
                    11.2
                    
                  
                  Defining Gradient Descent
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/11/gradient_convexity.html"
                >
                  
                    11.3
                    
                  
                  Convexity
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/11/gradient_stochastic.html"
                >
                  
                    11.4
                    
                  
                  Stochastic Gradient Descent
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/12/prob_and_gen.html"
        >
          
            12.
          
          Probability and Generalization
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/12/prob_random_vars.html"
                >
                  
                    12.1
                    
                  
                  Random Variables
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/12/prob_exp_var.html"
                >
                  
                    12.2
                    
                  
                  Expectation and Variance
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/12/prob_risk.html"
                >
                  
                    12.3
                    
                  
                  Risk
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/13/linear_models.html"
        >
          
            13.
          
          Linear Regression
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/13/linear_tips.html"
                >
                  
                    13.1
                    
                  
                  Defining a Simple Linear Model
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/13/linear_grad.html"
                >
                  
                    13.2
                    
                  
                  Fitting the Model
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/13/linear_multiple.html"
                >
                  
                    13.3
                    
                  
                  Multiple Linear Regression
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/13/linear_projection.html"
                >
                  
                    13.4
                    
                  
                  A Geometric Perspective
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/13/linear_case_study.html"
                >
                  
                    13.5
                    
                  
                  Linear Regression Case Study
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/14/feature_engineering.html"
        >
          
            14.
          
          Feature Engineering
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/14/feature_one_hot.html"
                >
                  
                    14.1
                    
                  
                  One-Hot Encoding
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/14/feature_polynomial.html"
                >
                  
                    14.2
                    
                  
                  Polynomial Regression
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/15/bias_intro.html"
        >
          
            15.
          
          Bias-Variance Tradeoff
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections ">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/15/bias_risk.html"
                >
                  
                    15.1
                    
                  
                  Risk and Cost Minimization
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry c-sidebar__entry--active"
                  href="/ch/15/bias_modeling.html"
                >
                  
                    15.2
                    
                  
                  Model Bias and Variance
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/15/bias_cv.html"
                >
                  
                    15.3
                    
                  
                  Cross Validation
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/16/reg_intro.html"
        >
          
            16.
          
          Regularization
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/16/reg_intuition.html"
                >
                  
                    16.1
                    
                  
                  Regularization Intuition
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/16/reg_ridge.html"
                >
                  
                    16.2
                    
                  
                  L2 Regularization
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/16/reg_lasso.html"
                >
                  
                    16.3
                    
                  
                  L1 Regularization
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/17/classification_intro.html"
        >
          
            17.
          
          Classification
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/17/classification_prob.html"
                >
                  
                    17.1
                    
                  
                  Regression on Probabilities
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/17/classification_log_model.html"
                >
                  
                    17.2
                    
                  
                  Logistic Model
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/17/classification_cost.html"
                >
                  
                    17.3
                    
                  
                  Cross-Entropy Loss
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/17/classification_log_reg.html"
                >
                  
                    17.4
                    
                  
                  Using Logistic Regression
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/17/classification_cost_justification.html"
                >
                  
                    17.5
                    
                  
                  Justifying Cross-Entropy Loss
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/17/classification_sgd.html"
                >
                  
                    17.6
                    
                  
                  Fitting a Logistic Model
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/17/classification_sensitivity_specificity.html"
                >
                  
                    17.7
                    
                  
                  Evaluating Logistic Models
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/17/classification_multiclass.html"
                >
                  
                    17.8
                    
                  
                  Multiclass Classification
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/18/hyp_intro.html"
        >
          
            18.
          
          Statistical Inference
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/18/hyp_introduction.html"
                >
                  
                    18.1
                    
                  
                  Introduction to Hypothesis Testing
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/18/hyp_introduction_part2.html"
                >
                  
                    18.2
                    
                  
                  Permutation Testing
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/18/hyp_regression.html"
                >
                  
                    18.3
                    
                  
                  Bootstrapping for Linear Regression
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/18/hyp_studentized.html"
                >
                  
                    18.4
                    
                  
                  Studentized Bootstrap
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/18/hyp_phacking.html"
                >
                  
                    18.5
                    
                  
                  P-Hacking
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      
        <li class="c-sidebar__divider"></li>
        

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/19/vector_space_review.html"
        >
          
          Appendix: Vector Space Review
        </a>

        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/20/ref_intro.html"
        >
          
          Appendix: Reference Tables
        </a>

        

          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/20/ref_pandas.html"
                >
                  
                  pandas
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/20/ref_seaborn.html"
                >
                  
                  seaborn
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/20/ref_matplotlib.html"
                >
                  
                  matplotlib
                </a>
              </li>
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/ch/20/ref_sklearn.html"
                >
                  
                  scikit-learn
                </a>
              </li>
            
          </ul>
        
      </li>

      
    

      
      

      
      

      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ch/21/contributors.html"
        >
          
          Appendix: Contributors
        </a>

        
      </li>

      
    
  </ul>
</nav>


      <main class="c-textbook__page" tabindex="-1">
        <div class="o-wrapper c-sidebar-toggle">
  <!-- We show the sidebar by default so we use .is-active -->
  <button
    id="js-sidebar-toggle"
    class="hamburger hamburger--arrowalt is-active"
  >
    <span class="hamburger-box">
      <span class="hamburger-inner"></span>
    </span>
    <span class="c-sidebar-toggle__label">Toggle Sidebar</span>
  </button>
</div>

        <div class="o-wrapper">
          

<div id="ipython-notebook">
    <div class="buttons">
        <button class="interact-button js-nbinteract-widget">
            Show Widgets
        </button>
        <a class="interact-button" href="http://data100.datahub.berkeley.edu/user-redirect/git-pull?repo=https://github.com/DS-100/textbook&subPath=notebooks/15/bias_modeling.ipynb">Open on DataHub</a>
    </div>
    







  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="c1"># Clear previously defined variables</span>
<span class="o">%</span><span class="k">reset</span> -f

<span class="c1"># Set directory for data loading to work properly</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/notebooks/15&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

  </div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="c1"># Ignore numpy dtype warnings. These warnings are caused by an interaction</span>
<span class="c1"># between numpy and Cython and can be safely ignored.</span>
<span class="c1"># Reference: https://stackoverflow.com/a/40846742</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;numpy.dtype size changed&quot;</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;numpy.ufunc size changed&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="k">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">fixed</span><span class="p">,</span> <span class="n">interact_manual</span>
<span class="kn">import</span> <span class="nn">nbinteract</span> <span class="k">as</span> <span class="nn">nbi</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s1">&#39;talk&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_columns</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="c1"># This option stops scientific notation for pandas</span>
<span class="c1"># pd.set_option(&#39;display.float_format&#39;, &#39;{:.2f}&#39;.format)</span>
</pre></div>

    </div>
</div>
</div>

  </div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="k">def</span> <span class="nf">df_interact</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">7</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Outputs sliders that show rows and columns of df</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="nf">peek</span><span class="p">(</span><span class="n">row</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">row</span><span class="p">:</span><span class="n">row</span> <span class="o">+</span> <span class="n">nrows</span><span class="p">,</span> <span class="n">col</span><span class="p">:</span><span class="n">col</span> <span class="o">+</span> <span class="n">ncols</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">ncols</span><span class="p">:</span>
        <span class="n">interact</span><span class="p">(</span><span class="n">peek</span><span class="p">,</span> <span class="n">row</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">-</span> <span class="n">nrows</span><span class="p">,</span> <span class="n">nrows</span><span class="p">),</span> <span class="n">col</span><span class="o">=</span><span class="n">fixed</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">interact</span><span class="p">(</span><span class="n">peek</span><span class="p">,</span>
                 <span class="n">row</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">-</span> <span class="n">nrows</span><span class="p">,</span> <span class="n">nrows</span><span class="p">),</span>
                 <span class="n">col</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> <span class="o">-</span> <span class="n">ncols</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;(</span><span class="si">{}</span><span class="s1"> rows, </span><span class="si">{}</span><span class="s1"> columns) total&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model-Bias-and-Variance">Model Bias and Variance<a class="anchor-link" href="#Model-Bias-and-Variance">&#182;</a></h2><p>We have previously seen that our choice of model has two basic sources of error.</p>
<p>Our model may be too simple—a linear model is not able to properly fit data generated from a quadratic process, for example. This type of error arises from model <strong>bias</strong>.</p>
<p>Our model may also fit the random noise present in the data—even if we fit a quadratic process using a quadratic model, the model may predict different outcomes than the true process produces. This type of error arises from model <strong>variance</strong>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Bias-Variance-Decomposition">The Bias-Variance Decomposition<a class="anchor-link" href="#The-Bias-Variance-Decomposition">&#182;</a></h2><p>We can make the statements above more precise by decomposing our formula for model risk. Recall that the <strong>risk</strong> for a model $ f_\hat{\theta} $ is the expected loss for all possible sets of training data $ X $, $ y $ and all input-output points $ z$, $ \gamma $ in the population:</p>
<p>$$
\begin{aligned}
R(f_\hat{\theta}) = \mathbb{E}[ \ell(\gamma, f_\hat{\theta} (z)) ]
\end{aligned}
$$</p>
<p>We denote the process that generates the true population data as $ f_\theta(x) $. The output point $ \gamma $ is generated by our population process plus some random noise in data collection: $ \gamma_i = f_\theta(z_i) + \epsilon $.  The random noise $ \epsilon $ is a random variable with a mean of zero: $ \mathbb{E}[\epsilon] = 0 $.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If we use the squared error as our loss function, the above expression becomes:</p>
<p>$$
\begin{aligned}
R(f_\hat{\theta}) = \mathbb{E}[ (\gamma - f_\hat{\theta} (z))^2 ]
\end{aligned}
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With some algebraic manipulation, we can show that the above expression is equivalent to:</p>
<p>$$
\begin{aligned}
R(f_\hat{\theta}) = (\mathbb{E}[f_\hat{\theta}(z)] - f_\theta(z))^2 + \text{Var}(f_\hat{\theta}(z)) + \text{Var}(\epsilon)
\end{aligned}
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The first term in this expression, $ (\mathbb{E}[f_\hat{\theta}(z)] - f_\theta(z))^2 $, is a mathematical expression for the bias of the model. (Technically, this term represents the bias squared, $\text{bias}^2$.) The bias is equal to zero if in the long run our choice of model $ f_\hat{\theta}(z) $ predicts the same outcomes produced by the population process $ f_\theta(z) $. The bias is high if our choice of model makes poor predictions of the population process even when we have the entire population as our dataset.</p>
<p>The second term in this expression, $ \text{Var}(f_\hat{\theta}(z)) $, represents the model variance. The variance is low when the model's predictions don't change much when the model is trained on different datasets from the population. The variance is high when the model's predictions change greatly when the model is trained on different datasets from the population.</p>
<p>The third and final term in this expression, $ \text{Var}(\epsilon) $, represents the irreducible error or the noise in the data generation and collection process. This term is small when the data generation and collection process is precise or has low variation. This term is large when the data contain large amounts of noise.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Derivation-of-Bias-Variance-Decomposition">Derivation of Bias-Variance Decomposition<a class="anchor-link" href="#Derivation-of-Bias-Variance-Decomposition">&#182;</a></h2><p>To begin the decomposition, we start with the mean squared error:</p>
<p>$$\mathbb{E}[(\gamma - f_{\hat{\theta}}(z))^2]$$</p>
<p>And expand the square and apply linearity of expectation:</p>
<p>$$ =\mathbb{E}[\gamma^2 -2\gamma f_{\hat{\theta}} +f_\hat{\theta}(z)^2]$$<br>
$$= \mathbb{E}[\gamma^2] - \mathbb{E}[2\gamma f_{\hat{\theta}}(z)] + \mathbb{E}[f_{\hat{\theta}}(z)^2]$$</p>
<p>Because $ \gamma $ and $f_{\hat{\theta}}(z)$ are independent (the model outputs and population observations don't depend on each other), we can say that $\mathbb{E}[2\gamma f_{\hat{\theta}}(z)] = \mathbb{E}[2\gamma]  \mathbb{E}[f_{\hat{\theta}}(z)] $. We then substitute $f_\theta(z) + \epsilon$ for $\gamma$:</p>
<p>$$ =\mathbb{E}[(f_\theta(z) + \epsilon)^2] - \mathbb{E}[2(f_\theta(z) + \epsilon)] \mathbb{E}[f_{\hat{\theta}}(z)] + \mathbb{E}[f_{\hat{\theta}}(z)^2]$$</p>
<p>Simplifiying some more: (Note that $\mathbb{E}[f_\theta(z)] = f_\theta(z)$ because $f_\theta(z)$ is a deterministic function, given a particular query point $ z $.)</p>
<p>$$ =\mathbb{E}[f_\theta(z)^2 + 2f_\theta(z) \epsilon + \epsilon^2] - (2f_\theta(z) + \mathbb{E}[2\epsilon]) \mathbb{E}[f_{\hat{\theta}}(z)] + \mathbb{E}[f_{\hat{\theta}}(z)^2]$$</p>
<p>Applying linearity of expectation again:</p>
<p>$$= f_\theta(z)^2 + 2f_\theta(z)\mathbb{E}[\epsilon] + \mathbb{E}[\epsilon^2] - (2f_\theta(z) + 2\mathbb{E}[\epsilon]) \mathbb{E}[f_{\hat{\theta}}(z)] + \mathbb{E}[f_{\hat{\theta}}(z)^2]$$</p>
<p>Noting that $\big( \mathbb{E}[\epsilon] = 0 \big) =&gt; \big( \mathbb{E}[\epsilon^2] = \text{Var}(\epsilon) \big)$ because $\text{Var}(\epsilon) = \mathbb{E}[\epsilon^2]-\mathbb{E}[\epsilon]^2$:</p>
<p>$$ = f_\theta(z)^2 + \text{Var}(\epsilon) - 2f_\theta(z) \mathbb{E}[f_{\hat{\theta}}(z)] + \mathbb{E}[f_{\hat{\theta}}(z)^2]$$</p>
<p>We can then rewrite the equation as:</p>
<p>$$ = f_\theta(z)^2 + \text{Var}(\epsilon) - 2f_\theta(z) \mathbb{E}[f_{\hat{\theta}}(z)] + \mathbb{E}[f_{\hat{\theta}}(z)^2] -  \mathbb{E}[f_{\hat{\theta}}(z)]^2 + \mathbb{E}[f_{\hat{\theta}}(z)]^2$$</p>
<p>Because $ \mathbb{E}[f_{\hat{\theta}}(z)^2] -  \mathbb{E}[f_{\hat{\theta}}(z)]^2 = Var(f_{\hat{\theta}}(z))$:</p>
<p>$$ =  f_\theta(z)^2 - 2f_\theta(z) \mathbb{E}[f_{\hat{\theta}}(z)] + \mathbb{E}[f_{\hat{\theta}}(z)]^2 + Var(f_{\hat{\theta}}(z)) + \text{Var}(\epsilon)$$</p>
<p>$$ = (f_\theta(z) - \mathbb{E}[f_{\hat{\theta}}(z)])^2 + Var(f_{\hat{\theta}}(z)) + \text{Var}(\epsilon) $$<br>
$$= \text{bias}^2 + \text{model variance} + \text{noise}$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To pick a model that performs well, we seek to minimize the risk. To minimize the risk, we attempt to minimize the bias, variance, and noise terms of the bias-variance decomposition. Decreasing the noise term typically requires improvements to the data collection process—purchasing more precise sensors, for example. To decrease bias and variance, however, we must tune the complexity of our models. Models that are too simple have high bias; models that are too complex have high variance. This is the essence of the <em>bias-variance tradeoff</em>, a fundamental issue that we face in choosing models for prediction.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Example:-Linear-Regression-and-Sine-Waves">Example: Linear Regression and Sine Waves<a class="anchor-link" href="#Example:-Linear-Regression-and-Sine-Waves">&#182;</a></h2><p>Suppose we are modeling data generated from the oscillating function shown below.</p>

</div>
</div>
</div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LinearRegression</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">Line</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;Line&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;x_start&#39;</span><span class="p">,</span> <span class="s1">&#39;x_end&#39;</span><span class="p">,</span> <span class="s1">&#39;y_start&#39;</span><span class="p">,</span> <span class="s1">&#39;y_end&#39;</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">noise</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">draw</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">points</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">points</span><span class="p">)</span> <span class="o">+</span> <span class="n">noise</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fit_line</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">x_end</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Line</span><span class="p">(</span><span class="n">x_start</span><span class="p">,</span> <span class="n">x_end</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_start</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_end</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">population_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="n">population_y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">population_x</span><span class="p">)</span>

<span class="n">avg_line</span> <span class="o">=</span> <span class="n">fit_line</span><span class="p">(</span><span class="n">population_x</span><span class="p">,</span> <span class="n">population_y</span><span class="p">)</span>

<span class="n">datasets</span> <span class="o">=</span> <span class="p">[</span><span class="n">draw</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">)]</span>
<span class="n">random_lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">fit_line</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

  </div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">population_x</span><span class="p">,</span> <span class="n">population_y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;True underlying data generation process&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_png output_subarea ">
<img src="/notebooks-images/bias_modeling_12_0.png"
>
</div>

</div>

</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If we randomly draw a dataset from the population, we may end up with the following:</p>

</div>
</div>
</div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">xs</span><span class="p">,</span> <span class="n">ys</span> <span class="o">=</span> <span class="n">draw</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;One set of observed data&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_png output_subarea ">
<img src="/notebooks-images/bias_modeling_14_0.png"
>
</div>

</div>

</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Suppose we draw many sets of data from the population and fit a simple linear model to each one. Below, we plot the population data generation scheme in blue and the model predictions in green.</p>

</div>
</div>
</div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">population_x</span><span class="p">,</span> <span class="n">population_y</span><span class="p">)</span>

<span class="k">for</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">x_end</span><span class="p">,</span> <span class="n">y_start</span><span class="p">,</span> <span class="n">y_end</span> <span class="ow">in</span> <span class="n">random_lines</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x_start</span><span class="p">,</span> <span class="n">x_end</span><span class="p">],</span> <span class="p">[</span><span class="n">y_start</span><span class="p">,</span> <span class="n">y_end</span><span class="p">],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Population vs. linear model predictions&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_png output_subarea ">
<img src="/notebooks-images/bias_modeling_16_0.png"
>
</div>

</div>

</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The plot above clearly shows that a linear model will make prediction errors for this population. We may decompose the prediction errors into bias, variance, and irreducible noise. We illustrate bias of our model by showing that the long-run average linear model will predict different outcomes than the population process:</p>

</div>
</div>
</div>

  

  <div class="
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">population_x</span><span class="p">,</span> <span class="n">population_y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Population&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">avg_line</span><span class="o">.</span><span class="n">x_start</span><span class="p">,</span> <span class="n">avg_line</span><span class="o">.</span><span class="n">x_end</span><span class="p">],</span>
         <span class="p">[</span><span class="n">avg_line</span><span class="o">.</span><span class="n">y_start</span><span class="p">,</span> <span class="n">avg_line</span><span class="o">.</span><span class="n">y_end</span><span class="p">],</span>
         <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span>
         <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Long-run average linear model&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Bias of linear model&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_png output_subarea ">
<img src="/notebooks-images/bias_modeling_18_0.png"
>
</div>

</div>

</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The variance of our model is the variation of the model predictions around the long-run average model:</p>

</div>
</div>
</div>

  

  <div class="
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">x_end</span><span class="p">,</span> <span class="n">y_start</span><span class="p">,</span> <span class="n">y_end</span> <span class="ow">in</span> <span class="n">random_lines</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x_start</span><span class="p">,</span> <span class="n">x_end</span><span class="p">],</span> <span class="p">[</span><span class="n">y_start</span><span class="p">,</span> <span class="n">y_end</span><span class="p">],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">avg_line</span><span class="o">.</span><span class="n">x_start</span><span class="p">,</span> <span class="n">avg_line</span><span class="o">.</span><span class="n">x_end</span><span class="p">],</span>
         <span class="p">[</span><span class="n">avg_line</span><span class="o">.</span><span class="n">y_start</span><span class="p">,</span> <span class="n">avg_line</span><span class="o">.</span><span class="n">y_end</span><span class="p">],</span>
         <span class="n">linewidth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Variance of linear model&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_png output_subarea ">
<img src="/notebooks-images/bias_modeling_20_0.png"
>
</div>

</div>

</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, we illustrate the irreducible error by showing the deviations of the observed points from the underlying population process.</p>

</div>
</div>
</div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">population_x</span><span class="p">,</span> <span class="n">population_y</span><span class="p">)</span>


<span class="n">xs</span><span class="p">,</span> <span class="n">ys</span> <span class="o">=</span> <span class="n">draw</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Irreducible error&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_png output_subarea ">
<img src="/notebooks-images/bias_modeling_22_0.png"
>
</div>

</div>

</div>
</div>

  </div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Bias-Variance-In-Practice">Bias-Variance In Practice<a class="anchor-link" href="#Bias-Variance-In-Practice">&#182;</a></h2><p>In an ideal world, we would minimize the expected prediction error for our model over all input-output points in the population.  However, in practice, we do not know the population data generation process and thus are unable to precisely determine a model's bias, variance, or irreducible error. Instead, we use our observed dataset as an approximation to the population.</p>
<p>As we have seen, however, achieving a low training error does not necessarily mean that our model will have a low test error as well. It is easy to obtain a model with extremely low bias and therefore low training error by fitting a curve that passes through every training observation. However, this model will have high variance which typically leads to high test error. Conversely, a model that predicts a constant has low variance but high bias. Fundamentally, this occurs because training error reflects the bias of our model but not the variance; the test error reflects both. In order to minimize test error, our model needs to simultaneously achieve low bias and low variance. To account for this, we need a way to simulate test error without using the test set. This is generally done using cross validation.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Takeaways">Takeaways<a class="anchor-link" href="#Takeaways">&#182;</a></h2><p>The bias-variance tradeoff allows us to more precisely describe the modeling phenomena that we have seen thus far.</p>
<p>Underfitting is typically caused by too much bias; overfitting is typically caused by too much model variance.</p>
<p>Collecting more data reduces variance. For example, the model variance of linear regression goes down by a factor of $ 1
/n $, where $ n $ is the number of data points. Thus, doubling the dataset size halves the model variance, and collecting many data points will cause the variance to approach 0. One recent trend is to select a model with low bias and high intrinsic variance (e.g. a neural network) and collect many data points so that the model variance is low enough to make accurate predictions. While effective in practice, collecting enough data for these models tends to require large amounts of time and money.</p>
<p>Collecting more data reduces bias if the model can fit the population process exactly. If the model is inherently incapable of modeling the population (as in the example above), even infinite data cannot get rid of model bias.</p>
<p>Adding a useful feature to the data, such as a quadratic feature when the underlying process is quadratic, reduces bias. Adding a useless feature rarely increases bias.</p>
<p>Adding a feature, whether useful or not, typically increases model variance since each new feature adds a parameter to the model. Generally speaking, models with many parameters have many possible combinations of parameters and therefore have higher variance than models with few parameters. In order to increase a model's prediction accuracy, a new feature should decrease bias more than it increases variance.</p>
<p>Removing features will typically increase bias and can cause underfitting. For example, a simple linear model has higher model bias than the same model with a quadratic feature added to it. If the data were generated from a quadratic phenomenon, the simple linear model underfits the data.</p>
<p>In the plot below, the X-axis measures model complexity and the Y-axis measures magnitude. Notice  how as model complexity increases, model bias strictly decreases and model variance strictly increases. As we choose more complex models, the test error first decreases then increases as the increased model variance outweighs the decreased model bias.</p>
<p><img src="https://raw.githubusercontent.com/DS-100/textbook/master/assets/bias_modeling_bias_var_plot.png" alt="bias_modeling_bias_var_plot.png"></p>
<p>As the plot shows, a model with high complexity can achieve low training error but can fail to generalize to the test set because of its high model variance. On the other hand, a model with low complexity will have low model variance but can also fail to generalize because of its high model bias. To select a useful model, we must strike a balance between model bias and variance.</p>
<p>As we add more data, we shift the curves on our plot to the right and down, reducing bias and variance:</p>
<p><img src="https://raw.githubusercontent.com/DS-100/textbook/master/assets/bias_modeling_bias_var_shift.png" alt="bias_modeling_bias_var_shiftt.png"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary">Summary<a class="anchor-link" href="#Summary">&#182;</a></h2><p>The bias-variance tradeoff reveals a fundamental problem in modeling. In order to minimize model risk, we use a combination of feature engineering, model selection, and cross-validation to balance bias and variance.</p>

</div>
</div>
</div>


</div>



          <nav class="c-page__nav">
  
    <a id="js-page__nav__prev" class="c-page__nav__prev" href="/ch/15/bias_risk.html">
      〈 <span class="u-margin-right-tiny"></span> Previous
    </a>
  

  
    <a id="js-page__nav__next" class="c-page__nav__next" href="/ch/15/bias_cv.html">
      Next <span class="u-margin-right-tiny"></span> 〉
    </a>
  
</nav>

        </div>
      </main>
    </div>

    <script>
      window.ga =
  window.ga ||
  function() {
    ;(ga.q = ga.q || []).push(arguments)
  }
ga.l = +new Date()
ga('create', 'UA-113006011-1', 'auto')
ga('send', 'pageview')

    </script>
  </body>
</html>
